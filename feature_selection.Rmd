---
title: "Feature selection tutorial with medioambiental dataset"
author: "Diabb Zegpi"
output:
  html_document:
    df_print: paged
---

## Correlation

If you're working with a model that asumes linear relationship, correlation is a good first step for makeing a list of candidate predictors. For this example, we're going to use *CO2*, which contains the results of an experiment on the cold tolerance of grass. Grass samples from two regions (Quebec and Mississippi) were grown in either a chilled or nonchilled environment, and their $CO_2$ uptake rate was tested.

```{r echo = FALSE, message = FALSE}
library(tidyverse)
library(kableExtra)
library(broom)
co2 <- as_tibble(CO2)
head(co2) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)
```

The analysis will be oriented in the `tidyverse` approach. Let's start with some exploratory analysis.

```{r echo = FALSE, message = FALSE}
theme_set(theme_light())

ggplot(co2, aes(conc, uptake)) +
  geom_point() +
  geom_smooth(se = FALSE, size = 1.5, alpha = 0.3) +
  expand_limits(y = 0, x = 0) +
  labs(title = bquote("Do we have a linear pattern between" ~ CO[2] ~ "emissions and the uptake rate?"),
       y = expression(paste("Uptake rate [", mu, "mol/", m^2, "]", sep = "")),
       x = "Ambient carbon dioxide concentrations [mL/L]")
```

The first impression is that the uptake rate increases linearly until ambient carbon dioxide concentration reach 350 mL/L. Then, the slope of the curve approaches to zero. One interpretation is that grass plants get saturated at high levels of carbon dioxide concentration (*over 350*). In any case, the correlation exist and is **direct and moderate**.

```{r}
cor.test(co2$conc, co2$uptake) %>% tidy() %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)
```


Here, the analysis bifurcates into two approaches:

1. Treat the variable **as a factor**
2. Compare the ambient carbon dioxide concentrations between grass plants. Perhaps, the uptake rate relies on the location.

In both cases, we dig into the categorical variables.

## ANOVA

```{r echo = FALSE}
co2 %>% 
  mutate(Treatment = str_to_sentence(Treatment),
         Treatment = recode(Treatment, Nonchilled = "Non chilled")) %>%
  ggplot(aes(uptake, fill = Treatment)) +
  geom_histogram(bins = 10, color = "black") +
  facet_wrap(~ Treatment, ncol = 2) +
  guides(fill = FALSE) +
  labs(title = bquote("What is the uptake rate of" ~ CO[2] ~ "in grass plants?"),
       subtitle = "42 observations each",
       x = expression(paste("Uptake rate [", mu, "mol/", m^2, "]", sep = "")),
       y = NULL) +
  scale_y_continuous(labels = NULL) +
  theme(axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        strip.text = element_text(size = 12, face = "bold"),
        strip.background = element_rect(fill = "black"))
```

Apparently, non chilled plants tend to uptake more $CO_2$ than chilled plants. The question is if the difference is statistically significant or not. With that purpose, we will performance an ***ANOVA*** test to see if the *levels* of **Treatment** make a difference in de **uptake rate**.

To perform ***ANOVA*** correctly, we have to ensure that de levels of the cuantitative variable are normally distributed, We do that with the *Shapiro-Wilk test*. 

```{r}
shapiro.test(filter(co2, Treatment == "nonchilled") %>% pull(uptake)) %>% 
  tidy() %>%
  rbind(shapiro.test(filter(co2, Treatment == "chilled") %>% pull(uptake)) %>% tidy()) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)

```

Both *p-values* are below 0.05, therefore we reject the null hypothesis and conclude that *uptake*, according to *Treatment* levels, is normally distributed.

Now is time for ***ANOVA test***.
$$H_0: \mu_A = \mu_B \\ H_1: \mu_A \neq \mu_B \\ A\ and\ B\ are\ levels\ of\ Treatment$$

```{r}
modelo_anova <- aov(uptake ~ Treatment, data = co2)
tidy(modelo_anova) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)
```

According to the test, Treatment is meaningfull for explaining the variance of uptake, but is there a chilling effect making variate the uptake rate? The **Honest Significant Difference test** (or *Tukey's test*) creates confidencenintervals following a studentized range distribution to compare the means of a factor's levels and answer this question.

```{r}
TukeyHSD(modelo_anova, conf.level = 0.95) %>%
  tidy() %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)
```

```{r echo = FALSE}
co2 %>% 
  mutate(Treatment = str_to_sentence(Treatment),
         Treatment = recode(Treatment, Nonchilled = "Non chilled")) %>% 
  ggplot(aes(Treatment, uptake, fill = Treatment)) +
  geom_boxplot(alpha = 0.7, width = 0.5) +
  geom_jitter(position = position_jitter(width = 0.2)) +
  scale_x_discrete(labels = NULL) +
  theme(legend.position = "bottom",
        panel.grid = element_blank(),
        axis.ticks.x = element_blank(),
        legend.text = element_text(size = 12),
        legend.title = element_text(size = 12)) +
  labs(x = NULL,
       y = bquote("rate of" ~ CO[2] ~ "uptake"),
       title = "How difference the uptake averages are compared \nto treatment levels?") +
  scale_fill_discrete(name = "Treatment:")
  
```

## Conclusion

* Treatment's variance is significant to explain uptake's.
* The **Tukey test** revealed that levels of treatment make a difference in the rate of $CO_2$ uptake on these grass plants.
* Using treatment as a feature to predict uptake is a correct decision.

## Chi-squared

In order to select the most important features for building a predictive model, we can apply the *chi-square test* to determine if the response is dependent on the given variables. Like all statistical tests, chi-squared test assumes a null hypothesis and an alternate hypothesis. The general practice is, if the p-value that comes out in the result is less than a pre-determined significance level, which is 0.05 usually, then we reject the null hypothesis.

$$H_0: the\ two\ variables\ are\ independent\\ H_1: the\ two\ variables\ are\ related$$

Chi-squared receives categorical data and make a comparisson between the actual and expected effect on the response variable. The question that attempts to ans is: are the variables related? Because the numerical nature of some variables, the `chi.squared` function of `FSelector` package discretizes all the continuous colums in the dataset.

```{r message = FALSE}
library(FSelector)
chi.squared(uptake ~ ., data = co2) %>% # cutoff.k(3) %>% as.simple.formula("uptake") to see top 3 variables in a formula
  mutate(feature = row.names(.)) %>% 
  as_tibble() %>% 
  arrange(desc(attr_importance)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)
```

`chi.squared` shows weigths of discrete attributes basing on a chi-squared test. More information available in [FSelector Package Documentation](https://cran.r-project.org/web/packages/FSelector/FSelector.pdf). 

You can also use `chisq.test` from `stats` to get more information out of the test, like de statistic, p-values and degrees of freedom, but you must discretize your data manually.

```{r message = FALSE, warning = FALSE}
co2 %>%
  mutate(uptake_discretized = arules::discretize(uptake, method = "cluster", labels = c("low", "medium", "high")),
         conc_discretized = arules::discretize(uptake, method = "cluster", labels = c("low", "medium", "high"))) %>% 
  select(-conc, -uptake) %>% 
  gather(feature, levels, -uptake_discretized) %>% 
  group_by(feature) %>% 
  nest() %>% 
  mutate(chi_squared = map_dbl(data, ~ chisq.test(.x$uptake_discretized, .x$levels, correct = FALSE)$statistic),
         p_value = map_dbl(data, ~ chisq.test(.x$uptake_discretized, .x$levels, correct = FALSE)$p.value)) %>% 
  select(-data) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)
```

## Conclusion

Using all four features for predicting future variance of $CO_2$ uptake rate it's statistically correct. Here the feature selection ends and the model comparisson begins. The usual models to use with few and categorical data are **decission trees** and **random forest**, but you can also keep the numerical version of uptake and use a **regression**.